{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMSdg8uTyEjOua6AolNFKP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OVx2JPRNYs6X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f143056-ea7b-40ce-a568-e47521f837be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['car', 'auto', 'automobile', 'machine', 'motorcar', 'car', 'railcar', 'railway_car', 'railroad_car', 'car', 'gondola', 'car', 'elevator_car', 'cable_car', 'car']\n",
            "Original Sentence: During our expedition, we encountered diverse animals such as eagles, trout, and rabbits.\n",
            "Replaced Sentence: During our expedition, we meet diverse beast such as eagles, trout, and lapin.\n",
            "The lowest top synset: animal\n",
            "Original Sentence: navigated through different terrains like mountains, forests, and rivers.\n",
            "Replaced Sentence: pilot through unlike terrains like mountains, woods, and rivers.\n",
            "The lowest top synset: abstraction\n",
            "Original Sentence: and used equipment including compasses, maps, and binoculars.\n",
            "Replaced Sentence: and used equipment include ambit, maps, and opera glasses.\n",
            "The lowest top synset: instrument\n"
          ]
        }
      ],
      "source": [
        "# Input is English text\n",
        "# The outputs:\n",
        "# Tokenize the text into sentences\n",
        "# For each sentence:\n",
        "# The lowest top synset(s) that are shared among most of the\n",
        "# core words in the sentence\n",
        "# Determine the most appropriate synsets that represent the\n",
        "# words in the sentence\n",
        "# Replaces 3-5 words in the sentence so that the sentence\n",
        "# appears the same\n",
        "import re\n",
        "import random\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.wsd import lesk\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "word = \"car\"\n",
        "synset_list = wordnet.synsets(word)\n",
        "synonyms = []\n",
        "\n",
        "for synset in synset_list:\n",
        "    for lemma in synset.lemma_names():\n",
        "        synonyms.append(lemma)\n",
        "\n",
        "print(synonyms)\n",
        "\n",
        "def get_core_synsets(words):\n",
        "    synsets = [wordnet.synsets(word) for word in words if wordnet.synsets(word)]\n",
        "    return synsets\n",
        "\n",
        "def get_lowest_common_hypernyms(synsets):\n",
        "    hypernym_counts = {}\n",
        "    for synset_list in synsets:\n",
        "        for synset in synset_list:\n",
        "            for hypernym in synset.hypernym_paths()[0]:\n",
        "                hypernym_counts[hypernym] = hypernym_counts.get(hypernym, 0) + 1\n",
        "\n",
        "    # Find hypernyms shared by at least half of the core words\n",
        "    common_hypernyms = {\n",
        "        hypernym\n",
        "        for hypernym, count in hypernym_counts.items()\n",
        "        if count >= len(synsets) // 2\n",
        "    }\n",
        "\n",
        "    # Find the lowest common hypernyms among those shared by most core words\n",
        "    lowest_common = None\n",
        "    for hypernym in common_hypernyms:\n",
        "        if lowest_common is None or hypernym.min_depth() > lowest_common.min_depth():\n",
        "            lowest_common = hypernym\n",
        "\n",
        "    return lowest_common\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def replace_words_with_synonyms(sentence):\n",
        "    words = word_tokenize(sentence)\n",
        "    tagged_words = pos_tag(words)\n",
        "    replaced_sentence = sentence\n",
        "    replacements = 0\n",
        "    replaced_words = []\n",
        "\n",
        "    for word, tag in tagged_words:\n",
        "        if replacements >= 3:  # Limit the number of replacements\n",
        "            break\n",
        "\n",
        "        wordnet_pos = get_wordnet_pos(tag)  # Get the WordNet POS tag\n",
        "        if wordnet_pos and word.lower() not in replaced_words:  # Check if we have a valid POS tag and the word hasn't been replaced already\n",
        "            synset = lesk(sentence, word, wordnet_pos)  # Use Lesk algorithm to get the best synset\n",
        "            if synset:\n",
        "                synonyms = synset.lemma_names()\n",
        "                # Exclude the original word and any synonyms already in the sentence\n",
        "                synonyms = [synonym for synonym in synonyms if synonym.lower() != word.lower() and synonym.lower() not in sentence.lower()]\n",
        "                if synonyms:\n",
        "                    replacement = random.choice(synonyms).replace('_', ' ')\n",
        "                    # Replace only whole words to avoid partial matches\n",
        "                    replaced_sentence = re.sub(r'\\b' + re.escape(word) + r'\\b', replacement, replaced_sentence, count=1)\n",
        "                    replacements += 1\n",
        "                    replaced_words.append(word.lower())  # Add the word to the list of replaced words to avoid duplicate replacements\n",
        "\n",
        "    return replaced_sentence\n",
        "\n",
        "def get_wordnet_pos(treebank_tag):\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "# Input text\n",
        "input_text = \"During our expedition, we encountered diverse animals such as eagles, trout, and rabbits. navigated through different terrains like mountains, forests, and rivers. and used equipment including compasses, maps, and binoculars.\"\n",
        "\n",
        "\n",
        "# Step 1: Tokenize the input text into sentences\n",
        "sentences = sent_tokenize(input_text)\n",
        "\n",
        "# Process each sentence\n",
        "for sentence in sentences:\n",
        "    # Step 2: Tokenize the sentence into words\n",
        "    words = word_tokenize(sentence)\n",
        "\n",
        "    # Step 3: Determine the synsets for each word in the sentence\n",
        "    word_synsets = get_core_synsets(words)\n",
        "    #print(word_synsets)\n",
        "\n",
        "    # Step 4: Find the lowest common hypernyms shared among the core words\n",
        "    lowest_hypernym = get_lowest_common_hypernyms(word_synsets)\n",
        "\n",
        "    # Step 5: Choose the most appropriate synset that represents each word\n",
        "    # Assuming the first synset is the most appropriate for simplicity\n",
        "\n",
        "    appropriate_synsets = [synset_list[0] for synset_list in word_synsets if synset_list]\n",
        "\n",
        "    # Step 6: Replace 3-5 words in the sentence with their synonyms from the chosen synsets\n",
        "    replaced_sentence = replace_words_with_synonyms(sentence)\n",
        "\n",
        "    # ...\n",
        "    # Output the results\n",
        "    print(\"Original Sentence:\", sentence)\n",
        "    print(\"Replaced Sentence:\", replaced_sentence)\n",
        "    # Use the .name().split('.')[0] to print only the synset name without the extra symbols and information\n",
        "    if lowest_hypernym:\n",
        "        print(\"The lowest top synset:\", lowest_hypernym.name().split('.')[0])\n",
        "# ..."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ieFhEdLVJvnl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}